# vim: tabstop=8 expandtab shiftwidth=4 softtabstop=4

# ------------------------ Imports ----------------------------------#
import numpy as np  # arrays
import time         # time step
import math         # sqrt
import matplotlib.pyplot as plt # Plotting

# ------------------------ Constants  -------------------------------#

class sparc_controller:

    def __init__(self, control_range, ref_range, input_size, dc_radius_const=0.5):
        self.umin, self.umax = control_range
        self.refmin, self.refmax = ref_range
        self.xsize = input_size
        self.radius_update_const = dc_radius_const

# - Control Signal:
UMAX = 20.0     # Range Max 
UMIN = -20.0    # Range Min
U1 = 0.0 # Start control signal

# - Input Signal (Measured by sensors on the plant)
X_SIZE = 2  # Dimension of the input (measured by sensors of the plant)

# - Plant output reference (Measured by sensors on the plant)
REFMAX = 10.0     # Range Max
REFMIN = 0.0    # Range Min

# - Consequents update constant
C = (UMAX - UMIN)/(REFMAX - REFMIN)

# - Time Step
MAXSTEPS = 3000 # Max number of steps
STEPTIME = 0.50   # Step time in seconds

# - Radius
RADIUS_UPDATE_CONST = 0.5

# Instantiates figure for plotting results:
fig = plt.figure();
axes = fig.add_axes([0.1, 0.1, 0.8, 0.8])
ypoints = []
refpoints = []

# ------------------------ Main Program  ---------------------------#
def sparc():

    # Instantiates list of Clouds:
    clouds = []

    # Instantiates plant:
    y1 = 0.0
    plant_obj = Plant(y1, STEPTIME)

    # Global density recursive values
    g_csi = np.array([0.0]*(X_SIZE+1));
    g_b = 0.0;

    # Set Initial Controller output
    curr_u = U1

    # Start prev_ values:
    prev_y = 0.0
    prev_ref = 0.0

    # Run for k steps
    for k in range(1, MAXSTEPS):

        # Gets current time to ensure a minimum time-step duration.
        step_start = time.time()

        # Gets sample, and generates input
        curr_y = plant_obj.get_y()
        curr_ref = reference(k)
        curr_x  = generate_input(curr_y, prev_y, curr_ref, prev_ref, STEPTIME)

        # Stores on list for plotting:
        ypoints.append(curr_y)
        refpoints.append(curr_ref)

        # Print result (curr_ref - curr_y)
        print "Step:", k, " | y:", curr_y, " | err:", (curr_y - curr_ref), " | u:", curr_u, " | #Clouds:", len(clouds)

        # Initiates SPARC with the first cloud, with an initial
        # consequent given by U1, and updates the plant if first iteration.
        if k == 1:
            curr_z = np.append(curr_x, curr_u)
            sigma1 = np.array([0.0]*X_SIZE)
            clouds.append(DataCloud(curr_z, sigma1))
            plant_obj.update(curr_u)

            # Initializes array with membership degrees.
            # md[i] corresponds to the degree of membership of the sample xk to the Data Cloud i
            curr_md = np.array([1.0]);  

            # Update global density recursive values
            g_csi = np.add(g_csi, curr_z)
            g_b = g_b + np.dot(curr_z, curr_z)

        # If its not the first iteration, compute:
        else: 

            # Updates the consequents of all clouds 
            for i in range(len(clouds)):
                clouds[i].update_consequent(prev_md[i], curr_x, prev_ref, curr_y, prev_u)

            # Calculate the new values of membership degrees, for the current sample.
            # Also finds out the data cloud that better describes the current sample. 
            ld_sum = 0.0
            curr_x_cloud = 0            # Index of the Best cloud.
            curr_x_cloud_ld = 0.0         # Best cloud local density.
            for i in range(len(clouds)):
                curr_md[i] = clouds[i].get_local_density(curr_x) 
                ld_sum = ld_sum + curr_md[i] 
                if curr_md[i] > curr_x_cloud_ld:
                    curr_x_cloud = i
                    curr_x_cloud_ld = curr_md[i] 
            curr_md = curr_md/float(ld_sum) 

            # Generate control signal
            curr_u = 0.0 
            for i in range(len(clouds)):
                curr_u = curr_u + curr_md[i]*clouds[i].get_consequent()

            # Prevent over-excursion
            if curr_u > UMAX:
                curr_u = UMAX
            if curr_u < UMIN:
                curr_u = UMIN

            # Update plant:
            plant_obj.update(curr_u);

            # Concatenates x and u to form z:
            curr_z = np.append(curr_x, curr_u)

            # Calculate Global Density of curr_z
            curr_gd = get_global_density(g_csi, g_b, curr_z, k)

            # Update Global Density values g_csi and g_b
            # Update global density recursive values
            g_csi = np.add(g_csi, curr_z)
            g_b = g_b + np.dot(curr_z, curr_z)

            # Tests to see if a new cloud is needed by doing the following (1) and (2):
            new_cloud_needed = True 

            # (1) Compares Z Global Density with all data clouds focal points global densities
            for c in clouds:
                gdf = get_global_density(g_csi, g_b, c.zf, k)
                if gdf > curr_gd:
                    new_cloud_needed = False
                    break

            # (2) Compares distance of zk to focal points with data cloud radiuses
            for c in clouds:
                if new_cloud_needed == True:
                    for r in c.r:
                        if np.linalg.norm(np.subtract(curr_z[:X_SIZE], c.zf[:X_SIZE])) < r/2.0:
                            new_cloud_needed = False
                            break
                else: break

            # If a new cloud is needed, creates a new cloud
            # Otherwise, adds the current point to the best matching cloud and checks
            # if the focal point has to be updated
            if new_cloud_needed == True:

                # Computes starting sigma (local scatter):
                sigma = np.array([0.0]*X_SIZE)
                for i in range(0, X_SIZE):
                    for c in clouds:
                        sigma[i] = sigma[i] + math.sqrt(c.sigma_sq[i])
                    sigma[i] = sigma[i]/len(clouds)

                # Creates new cloud with focal point zk and starting sigma
                clouds.append(DataCloud(curr_z, sigma))
                curr_md = np.append(curr_md, 0.0);
            else:
                # Computes cxk focal point global density (to check if focal point has to change)
                curr_x_cloud_gd = get_global_density(g_csi, g_b, clouds[curr_x_cloud].zf, k)

                # Compute focal point local density
                curr_x_cloud_zf = clouds[curr_x_cloud].zf
                curr_x_cloud_xf = curr_x_cloud_zf[:X_SIZE]
                ldf = clouds[curr_x_cloud].get_local_density(curr_x_cloud_xf)

                # Insert point to data cloud
                clouds[curr_x_cloud].add_point(curr_z)

                # Checks if the focal point needs to be updated:
                # curr_x_cloud_ld is the local density of curr_x relative to its cloud.
                # ldf is the local density of the focal point of curr_x's cloud.
                # curr_gd is the global density of curr_z
                # curr_x_cloud_gd is the global density of the focal point of curr_z's cloud.
                if  curr_x_cloud_ld > ldf and curr_gd > curr_x_cloud_gd:
                    clouds[curr_x_cloud].update_focal_point(curr_z)

        # Store last sample
        prev_u = curr_u
        prev_md = np.copy(curr_md)
        prev_ref = curr_ref
        prev_y = curr_y
        prev_ref = curr_ref

        # Wait until time-step minimum lenght is reached
        #step_end = time.time();
        #if (step_end - step_start) < STEPTIME:
        #    time.sleep(STEPTIME - (step_end - step_start))

    kpoints = range(1, MAXSTEPS)
    global axes
    axes.plot(kpoints, refpoints, 'r')
    axes.plot(kpoints, ypoints, 'b')
    plt.show() 
 # ------------------------ Global Methods  -------------------------#
def reference(k):
    """
    Outputs the desired output of the plant, on the time step k.
    Keyword arguments:
    k -- timestemp
    """
    refk = math.cos(0.05*k) + math.sin(0.07*k) + 3.7     

    return refk 

def get_global_density(g_csi, g_b, curr_z, k):
    """
    Calculates recursively the Global Density of point curr_z.

    Keyword arguments:
    g_csi -- current global csi (recursive calculation variable)
    cur_b -- current global b (recursive calculation variable)
    curr_z -- sample that will have its corresponding global density calculated.
    k -- current time step
    """

    # Computes global density of z and global density of f
    return (k-1)/((k-1)*(np.dot(curr_z, curr_z) +1) - 2*(np.dot(curr_z, g_csi)) + g_b) 

# ------------------------ Classes  ---------------------------------#
class DataCloud:
    """
    Class that represents a data cloud.

    It stores the following information in the form of instance variables:
    zf -- Focal point, composed by xf (data sample) and q (consequent) 
    csi, betha -- parameters for recursively calculation of local density
    r -- array of radii, one for each dimension of X.
    sigma_sq -- parameter for recursively calculation of radii.
    m -- number of points added so far
    z -- Last point added.
    """ 

    def __init__(self, z, sigma):
        """
        Initializes a DataCloud with one point z.
        Extracts x and u, setting u as the consequent q.

        Keyword arguments:
        z --
        sigma -- array containing the sigma starting value for the new DataCloud
        """

        # Gets plant input (x) and control signal (u) 
        # from z where z = [x', u']', setting them
        # as focal point (xf) and consequent (q) respectively.
        self.zf = z 

        # Local density calculation values
        csi1 = np.array([0.0]*X_SIZE)
        self.csi = np.add(csi1, self.zf[:X_SIZE])         

        betha1 = 0.0 
        self.betha = betha1 + np.dot(self.zf[:X_SIZE], self.zf[:X_SIZE]) 

        # Data Cloud Size
        self.m = 1

        # Data Cloud Radius
        # Each data cloud has X_SIZE radiuses, one for each dimension of x.
        # By definition the initial radius r1 is 1 for each dimension.
        self.r = np.array([1.0]*X_SIZE)

        # Local Scatter square (sigma_square), has to be stored for recursive calculation of
        # the radius. For each dimension of x, there's a sigma associated to it.
        # By definition the initial sigma sigma1 is 0        
        self.sigma_sq = np.power(sigma, 2)

    def update_focal_point(self, z):
        """
        Update focal point. Before calling this method, z has to be added to
        the Data Cloud by calling add_point(z).

        Keyword arguments:
        z -- datacloud point composed by x (data sample) and u (control signal) 
        """
        self.zf = z

    def __update_radius__(self, p, prev_r, sigma):
        """
        Update radius of the Data Cloud recursively.
        It needs to be called after a new point is added to the Cloud.

        Keyword arguments:
        p -- radius update constant, dictates how important is the new sample
        prev_r -- previous radius
        sigma -- current sigma (calculated with the new sample).
        """ 
        new_radius = p*prev_r + (1-p)*sigma 

    def __update_sigma_sq__(self, curr_x, xf, prev_sigma_sq, new_N, i):
        """
        Update the local scatter square of the Data Cloud recursively.
        The local scatter ( sigma ) is needed to update the radius.

        Keyword arguments:
        curr_x -- new sample added to data cloud
        xf -- focal point of the data cloud, before adding the new_x
        prev_sigma_sq -- previous value of sigma
        new_N -- new number of points on the data cloud (including the most recent new_x)
        i -- respective sigma dimention. dx is calculated only on this dimention.
        """

        dx = np.subtract(curr_x, xf)
        new_sigma_sq = ((new_N-1)*prev_sigma_sq + dx[i]**2)/new_N

        return new_sigma_sq

    def add_point(self, curr_z):
        """
        Associates a new point to the data cloud, updating the number of points
        updating local density values, sigma and radius.

        Keyword arguments:
        curr_z -- datacloud point composed by x (data sample) and u (control signal) 
        """

        # Update number of points
        self.m = self.m + 1;

        # Extract x
        x = curr_z[:X_SIZE]

        # Update Sigma
        xf = self.zf[:X_SIZE]
        for i in range(0, len(self.sigma_sq)):
            self.sigma_sq[i] = self.__update_sigma_sq__(x, xf, self.sigma_sq[i], self.m, i)

        # Update radius
        for index in range(0, len(self.r)):
            self.r[i] = self.__update_radius__(RADIUS_UPDATE_CONST, self.r[i], math.sqrt(self.sigma_sq[i]))

        # Update local density values 
        self.csi = np.add(self.csi, x) 
        self.betha = self.betha + np.dot(x, x)

    def get_local_density(self, x):
        """
        Recursively calculate the local density relative to the sample input x

        Keyword arguments:
        x -- an input of dimension XSIZE
        """
        ld = self.m/(self.m*(np.dot(x, x) + 1) - 2*(np.dot(x, self.csi)) + self.betha) 

        return ld

    def update_consequent(self, prev_md, curr_x, prev_ref, curr_y, prev_u):
        """
        Updates consequent

        Keyword arguments:
        curr_x -- current data sample of dimension XSIZE. 
        prev_md -- membership degree of the previous data sample related to this cloud.
        prev_ref -- previous reference value
        curr_y -- current plant output value
        prev_u -- previous control signal
        """

        # Calculate relative error:
        e = prev_ref - curr_y

        # Calculate consequent differential
        dq = C*prev_md*e

        # Checks if control signal maximum or minimum has been reached
        # to prevent penalization on these cases
        if (prev_u == UMIN) and (dq < 0):
            dq = 0;
        if (prev_u == UMAX) and (dq > 0):
            dq = 0;

        # Updates consequent
        q = self.get_consequent() + dq
        self.zf[-1] = q 

    def get_consequent(self):
        """
        Extract consequent value from the focal point of the data cloud (zf).
        """
        return self.zf[-1]

class WaterTank:

    def update(self, u):
        self.uk = u
        self.y = max(0.0, (self.y + self.t*(-math.sqrt(19.6*self.y) + self.uk)/((self.y**2)+1)))

    def __init__(self, y1, t):
        self.uk = 0 
        self.t = t
        self.y = y1

    def get_y(self):
        return self.y

def generate_input(y, yprev, ref, refprev, t):
    curr_e = y-ref
    prev_e = yprev - refprev

    x = np.array([curr_e, (curr_e-prev_e)/t])
    return x

class Plant:

    def __init__(self, y1, t):
       self.model = WaterTank(y1, t) 

    def get_y(self):
        return self.model.get_y()

    def update(self, u):
        return self.model.update(u)

# Run main program (sparc)
sparc()
